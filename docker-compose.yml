services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - kafka-net
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=zookeeper"

  kafka1:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka1
    labels:
      - "logging=true"
      - "service=kafka"
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka-net
    volumes:
      - kafka1-data:/var/lib/kafka/data
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=kafka1"

  kafka2:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka2
    labels:
      - "logging=true"
      - "service=kafka"
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka-net
    volumes:
      - kafka2-data:/var/lib/kafka/data
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=kafka2"

  kafka3:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka3
    labels:
      - "logging=true"
      - "service=kafka"
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29094,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka-net
    volumes:
      - kafka3-data:/var/lib/kafka/data
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=kafka3"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - kafka-net

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    restart: always
    networks:
      - kafka-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_FEATURE_TOGGLES_ENABLE=live
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
      - loki
    restart: always
    networks:
      - kafka-net

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    labels:
      - "logging=true"
      - "service=n8n"
    restart: always
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=matkhau
      - N8N_SECURE_COOKIE=false
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://localhost:5678/
      - GENERIC_TIMEZONE=Asia/Ho_Chi_Minh
    volumes:
      - n8n-data:/home/node/.n8n
    networks:
      - kafka-net
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=n8n"

  fastapi-n8n:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi-n8n-server
    labels:
      - "logging=true"
      - "service=fastapi-n8n"
    restart: always
    ports:
      - "12000:12000"
    environment:
      - PYTHONUNBUFFERED=1
    networks:
      - kafka-net
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=fastapi-n8n"

  mongodb:
    image: mongo:latest
    container_name: mongodb
    restart: always
    ports:
      - "27017:27017"
    networks:
      - kafka-net
    volumes:
      - mongo-data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: eup2030
      MONGO_INITDB_DATABASE: admin
    command: ["--auth"]
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
        labels: "service=mongodb"

  mongodb-exporter:
    image: bitnami/mongodb-exporter:latest
    container_name: mongodb-exporter
    restart: always
    ports:
      - "9216:9216"
    command:
      - '--mongodb.uri=mongodb://mongodb:27017'
      - '--mongodb.collstats-colls=user_fcm.users_fcm'
    depends_on:
      - mongodb
    networks:
      - kafka-net

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: kafka-exporter
    restart: always
    ports:
      - "9308:9308"
    command:
      - '--kafka.server=kafka1:29092'
      - '--kafka.server=kafka2:29093'
      - '--kafka.server=kafka3:29094'
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    networks:
      - kafka-net

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    user: "0:0"  # Chạy với root để tránh permission issues
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config/loki-config.yml:/etc/loki/loki-config.yml
      - loki-data:/tmp/loki
    command: -config.file=/etc/loki/loki-config.yml
    restart: always
    networks:
      - kafka-net

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    volumes:
      - ./promtail-config/promtail-config.yml:/etc/promtail/config.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ./logs:/app/logs:ro  # Mount thư mục logs từ host
      - /var/log:/var/log:ro  # Mount system logs
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    restart: always
    networks:
      - kafka-net

  # Node Exporter để monitor system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: always
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - kafka-net

  # Log Generator để test (có thể xóa nếu không cần)
  log-generator:
    image: alpine:latest
    container_name: log-generator
    labels:
      - "logging=true"
      - "service=test-app"
    volumes:
      - ./logs:/app/logs
    command: >
      sh -c "
        mkdir -p /app/logs &&
        while true; do
          echo \"\$$(date '+%Y-%m-%d %H:%M:%S') [INFO] Test log message - \$$RANDOM\" >> /app/logs/application.log;
          echo \"\$$(date '+%Y-%m-%d %H:%M:%S') [ERROR] Test error message - \$$RANDOM\" >> /app/logs/application.log;
          sleep 5;
        done
      "
    restart: always
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge
volumes:
  zookeeper-data:
  zookeeper-log:
  kafka1-data:
  kafka2-data:
  kafka3-data:
  n8n-data:
  mongo-data:
  prometheus-data:
  grafana-data:
  loki-data:
